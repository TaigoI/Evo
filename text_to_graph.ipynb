{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.11-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy)\n",
      "  Downloading thinc-8.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.13.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/tp/.local/lib/python3.10/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/tp/.local/lib/python3.10/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/tp/.local/lib/python3.10/site-packages (from spacy) (2.10.1)\n",
      "Requirement already satisfied: jinja2 in /home/tp/.local/lib/python3.10/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tp/.local/lib/python3.10/site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/tp/.local/lib/python3.10/site-packages (from spacy) (2.1.3)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/tp/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/tp/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/tp/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tp/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading blis-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/lib/python3/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.3)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.0.5-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tp/.local/lib/python3.10/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/tp/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading spacy-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.1/29.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (204 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.11-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
      "Downloading thinc-8.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.13.1-py3-none-any.whl (44 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.0.5-py3-none-any.whl (61 kB)\n",
      "Downloading marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, spacy-loggers, spacy-legacy, shellingham, numpy, murmurhash, mdurl, marisa-trie, cloudpathlib, catalogue, srsly, smart-open, preshed, markdown-it-py, language-data, blis, rich, langcodes, confection, typer, thinc, weasel, spacy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed blis-1.0.1 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.10 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.11 numpy-2.0.2 preshed-3.0.9 rich-13.9.4 shellingham-1.5.4 smart-open-7.0.5 spacy-3.8.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.3.2 typer-0.13.1 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:45:44.077536Z",
     "start_time": "2024-11-25T15:45:43.488297Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/tp/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to /home/tp/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pt-core-news-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.8.0/pt_core_news_lg-3.8.0-py3-none-any.whl (568.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.2/568.2 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pt-core-news-lg\n",
      "Successfully installed pt-core-news-lg-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_lg')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from json import loads as json_loads\n",
    "from json_repair import repair_json\n",
    "from itertools import combinations\n",
    "\n",
    "from nltk import download as nltk_download\n",
    "nltk_download('punkt')\n",
    "nltk_download('punkt_tab')\n",
    "nltk_download('rslp')\n",
    "\n",
    "from nltk import sent_tokenize as break_into_sentences\n",
    "from nltk.stem import RSLPStemmer as stemmer\n",
    "\n",
    "from re import search as re_search\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "import functools\n",
    "\n",
    "from spacy.cli import download as spacy_download\n",
    "spacy_download('pt_core_news_lg')\n",
    "\n",
    "from spacy import load as spacy_load\n",
    "nlp = spacy_load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:45:44.125076Z",
     "start_time": "2024-11-25T15:45:44.080115Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_client = OpenAI(\n",
    "  api_key=\"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\",\n",
    "  base_url=\"https://integrate.api.nvidia.com/v1\"\n",
    ")\n",
    "\n",
    "MODEL = \"meta/llama-3.1-405b-instruct\"\n",
    "\n",
    "@functools.cache\n",
    "def llm_inference(system_prompt:str, user_prompt:str):\n",
    "    completion = llm_client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":system_prompt},\n",
    "            {\"role\":\"user\",\"content\":user_prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        top_p=0.7,\n",
    "        max_tokens=2048,\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:45:44.204406Z",
     "start_time": "2024-11-25T15:45:44.202211Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_array(generated:str):\n",
    "    return re_search(r\"(\\[[\\W|\\w|\\s]*\\])\", generated).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:45:44.248605Z",
     "start_time": "2024-11-25T15:45:44.243687Z"
    }
   },
   "outputs": [],
   "source": [
    "knowledge_graph_prompt = \"\"\"\n",
    "Considando a frase abaixo, responda somente com o JSON abaixo, adicionando quantas entradas forem necessárias:\n",
    "[\n",
    "    {\"entidade_origem\": \"Nome da entidade\", \"relacionamento\": \"Uma única palavra, verbo no infinitivo, que descreve o relacionamento entre as entidades\", \"entidade_destino\": \"Nome da entidade\"},\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "def add_to_relationships(item:dict, relationships:list):   \n",
    "    origin_entity:list[str] = item[\"entidade_origem\"]\n",
    "    relationship:str = item[\"relacionamento\"]\n",
    "    destination_entity:list[str] = item[\"entidade_destino\"]\n",
    "    \n",
    "    relationships.append((origin_entity, relationship, destination_entity))\n",
    "\n",
    "@functools.cache\n",
    "def infer_knowledge_graph(phrase:str) -> tuple[str,str,str]:\n",
    "    generated = extract_array(\n",
    "        llm_inference(knowledge_graph_prompt, phrase)\n",
    "    )\n",
    "    \n",
    "    logging.info(generated)\n",
    "    \n",
    "    pair_relationships = []\n",
    "    try:\n",
    "        json_completion = json_loads(repair_json(generated))\n",
    "        for item in json_completion:\n",
    "            add_to_relationships(item, pair_relationships)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(\"FAILED TO GET GRAPH FROM COMPLETION\")\n",
    "        logging.error(e)\n",
    "    \n",
    "    return pair_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:45:44.293541Z",
     "start_time": "2024-11-25T15:45:44.290461Z"
    }
   },
   "outputs": [],
   "source": [
    "entity_grouping_prompt = \"\"\"\n",
    "Considere a lista de entidades que será fornecida abaixo. Seu objetivo é agrupar as entidades sinônimas, ou seja, que se referem a uma mesma coisa, utilizando nomes diferentes, siglas, etc. Também agrupe ações sinônimas, ou seja, que descrevem a mesma ação, mas que são descritas de formas diferentes.\n",
    "Responda EXCLUSIVAMENTE seguindo o formato JSON abaixo.\n",
    "[\n",
    "    {\"principal\": \"Nome principal\", \"apelidos\": [\"Outros nomes ou palavras que devem ser agrupados com esta\"]}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "@functools.cache\n",
    "def infer_name_replacement(phrase:str) -> dict[str,str]:\n",
    "    generated = extract_array(\n",
    "        llm_inference(entity_grouping_prompt, phrase)\n",
    "    )\n",
    "    logging.warning(generated)\n",
    "    \n",
    "    to_replace = {}\n",
    "    try:\n",
    "        json_completion:list[dict[str,list[str]]] = json_loads(generated)\n",
    "        for item in json_completion:\n",
    "            main_entity = item[\"principal\"]\n",
    "            for other_name in item[\"apelidos\"]:\n",
    "                to_replace[other_name.lower().strip()] = main_entity.lower().strip()\n",
    "    except Exception as e:\n",
    "        logging.error(\"FAILED TO GET REPLACEMENTS FROM COMPLETION\")\n",
    "        logging.error(e)\n",
    "    \n",
    "    return to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:45:44.338932Z",
     "start_time": "2024-11-25T15:45:44.336412Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_to_graph(text:str, should_break:bool=False) -> pd.DataFrame:\n",
    "    connections = []\n",
    "    sentences = [text]\n",
    "    \n",
    "    if(should_break):\n",
    "        sentences += break_into_sentences(text)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        connections += infer_knowledge_graph(sentence)    \n",
    "\n",
    "    return pd.DataFrame(connections, columns=[\"entity1\", \"relationship\", \"entity2\"]).apply(lambda x: x.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:45:44.384626Z",
     "start_time": "2024-11-25T15:45:44.381716Z"
    }
   },
   "outputs": [],
   "source": [
    "def unify_graph_terms(graphs: list[pd.DataFrame]) -> list[pd.DataFrame]:\n",
    "    all_named_entities = []\n",
    "    replacements = {}\n",
    "\n",
    "    all_named_entities = pd.concat([graph.melt()[\"value\"] for graph in graphs]).unique()\n",
    "\n",
    "    replacements = infer_name_replacement(str(all_named_entities))\n",
    "    graphs = [graph.map(lambda x: replacements.get(x.lower(), x).lower()).drop_duplicates() for graph in graphs]\n",
    "    replaced_named = {replacements.get(name, name) for name in all_named_entities}\n",
    "\n",
    "    return graphs, replaced_named, replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:46:05.118687Z",
     "start_time": "2024-11-25T15:46:05.117241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity1</th>\n",
       "      <th>relationship</th>\n",
       "      <th>entity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>djamila ribeiro</td>\n",
       "      <td>analisar</td>\n",
       "      <td>questão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mulheres</td>\n",
       "      <td>enfrentar</td>\n",
       "      <td>desafios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desafios</td>\n",
       "      <td>gerar</td>\n",
       "      <td>impactos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>governo</td>\n",
       "      <td>omitir</td>\n",
       "      <td>reconhecimento do trabalho de cuidado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mídia</td>\n",
       "      <td>influenciar</td>\n",
       "      <td>percepção do trabalho de cuidado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>djamila ribeiro</td>\n",
       "      <td>defender</td>\n",
       "      <td>solução</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>questão</td>\n",
       "      <td>sofrer</td>\n",
       "      <td>invisibilidade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mulheres</td>\n",
       "      <td>enfrentar</td>\n",
       "      <td>desafios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>desafios</td>\n",
       "      <td>gerar</td>\n",
       "      <td>impactos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>impactos</td>\n",
       "      <td>afetar</td>\n",
       "      <td>vidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trabalho de cuidado</td>\n",
       "      <td>ser reconhecido</td>\n",
       "      <td>reconhecimento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>omissão governamental</td>\n",
       "      <td>influenciar</td>\n",
       "      <td>problemática</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>influência midiática</td>\n",
       "      <td>influenciar</td>\n",
       "      <td>problemática</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  entity1     relationship  \\\n",
       "0         djamila ribeiro         analisar   \n",
       "1                mulheres        enfrentar   \n",
       "2                desafios            gerar   \n",
       "3                 governo           omitir   \n",
       "4                   mídia      influenciar   \n",
       "5         djamila ribeiro         defender   \n",
       "6                 questão           sofrer   \n",
       "7                mulheres        enfrentar   \n",
       "8                desafios            gerar   \n",
       "9                impactos           afetar   \n",
       "10    trabalho de cuidado  ser reconhecido   \n",
       "11  omissão governamental      influenciar   \n",
       "12   influência midiática      influenciar   \n",
       "\n",
       "                                  entity2  \n",
       "0                                 questão  \n",
       "1                                desafios  \n",
       "2                                impactos  \n",
       "3   reconhecimento do trabalho de cuidado  \n",
       "4        percepção do trabalho de cuidado  \n",
       "5                                 solução  \n",
       "6                          invisibilidade  \n",
       "7                                desafios  \n",
       "8                                impactos  \n",
       "9                                   vidas  \n",
       "10                         reconhecimento  \n",
       "11                           problemática  \n",
       "12                           problemática  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = \"\"\"De acordo com a pensadora brasileira Djamila Ribeiro, o primeiro passo a ser tomado para solucionar uma questão é tirá-la da invisibilidade. Porém, no contexto atual do Brasil, as mulheres enfrentam diversos desafios para que seu trabalho de cuidado seja reconhecido, gerando graves impactos em suas vidas, como a falta de destaque. Nesse sentido, essa problemática ocorre em virtude da omissão governamental e da influência midiática.\"\"\"\n",
    "original_graph = text_to_graph(original, True)\n",
    "original_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T15:46:05.160501Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity1</th>\n",
       "      <th>relationship</th>\n",
       "      <th>entity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>djamila ribeiro</td>\n",
       "      <td>analisar</td>\n",
       "      <td>problema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mulheres</td>\n",
       "      <td>enfrentar</td>\n",
       "      <td>obstáculos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>governo</td>\n",
       "      <td>negligenciar</td>\n",
       "      <td>trabalho de cuidado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meios de comunicação</td>\n",
       "      <td>influenciar</td>\n",
       "      <td>percepção do trabalho de cuidado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>djamila ribeiro</td>\n",
       "      <td>afirmar</td>\n",
       "      <td>ponto de partida para resolver um problema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ponto de partida para resolver um problema</td>\n",
       "      <td>ser</td>\n",
       "      <td>tornar o problema visível</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mulheres</td>\n",
       "      <td>enfrentar</td>\n",
       "      <td>obstáculos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>obstáculos</td>\n",
       "      <td>causar</td>\n",
       "      <td>consequências</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>consequências</td>\n",
       "      <td>afetar</td>\n",
       "      <td>vidas das mulheres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>governo</td>\n",
       "      <td>exercer</td>\n",
       "      <td>negligência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meios de comunicação</td>\n",
       "      <td>exercer</td>\n",
       "      <td>influência</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       entity1  relationship  \\\n",
       "0                              djamila ribeiro      analisar   \n",
       "1                                     mulheres     enfrentar   \n",
       "2                                      governo  negligenciar   \n",
       "3                         meios de comunicação   influenciar   \n",
       "4                              djamila ribeiro       afirmar   \n",
       "5   ponto de partida para resolver um problema           ser   \n",
       "6                                     mulheres     enfrentar   \n",
       "7                                   obstáculos        causar   \n",
       "8                                consequências        afetar   \n",
       "9                                      governo       exercer   \n",
       "10                        meios de comunicação       exercer   \n",
       "\n",
       "                                       entity2  \n",
       "0                                     problema  \n",
       "1                                   obstáculos  \n",
       "2                          trabalho de cuidado  \n",
       "3             percepção do trabalho de cuidado  \n",
       "4   ponto de partida para resolver um problema  \n",
       "5                    tornar o problema visível  \n",
       "6                                   obstáculos  \n",
       "7                                consequências  \n",
       "8                           vidas das mulheres  \n",
       "9                                  negligência  \n",
       "10                                  influência  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrase = \"\"\"Segundo a filósofa brasileira Djamila Ribeiro, o ponto de partida para resolver um problema é torná-lo visível. No entanto, no cenário atual do Brasil, as mulheres enfrentam inúmeros obstáculos para que o trabalho de cuidado que realizam seja valorizado, o que causa sérias consequências em suas vidas, como a ausência de reconhecimento. Essa situação é resultado, em grande parte, da negligência do governo e da influência exercida pelos meios de comunicação.\"\"\"\n",
    "\n",
    "paraphrase_graph = text_to_graph(paraphrase, True)\n",
    "paraphrase_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[\n",
      "    {\"principal\": \"trabalho de cuidado\", \"apelidos\": [\"cuidado\", \"reconhecimento do trabalho de cuidado\", \"percepção do trabalho de cuidado\"]},\n",
      "    {\"principal\": \"governo\", \"apelidos\": [\"omissão governamental\", \"influência governamental\"]},\n",
      "    {\"principal\": \"mídia\", \"apelidos\": [\"meios de comunicação\", \"influência midiática\"]},\n",
      "    {\"principal\": \"problema\", \"apelidos\": [\"questão\", \"problemática\", \"obstáculos\", \"consequências\"]},\n",
      "    {\"principal\": \"reconhecimento\", \"apelidos\": [\"reconhecimento do trabalho de cuidado\", \"ser reconhecido\"]},\n",
      "    {\"principal\": \"influência\", \"apelidos\": [\"influenciar\", \"influência midiática\", \"influência governamental\"]},\n",
      "    {\"principal\": \"negligenciar\", \"apelidos\": [\"omitir\", \"negligência\"]},\n",
      "    {\"principal\": \"afetar\", \"apelidos\": [\"sofrer\", \"afetar\", \"causar\"]},\n",
      "    {\"principal\": \"solução\", \"apelidos\": [\"ponto de partida para resolver um problema\", \"tornar o problema visível\"]},\n",
      "    {\"principal\": \"desafios\", \"apelidos\": [\"impactos\", \"obstáculos\", \"consequências\"]},\n",
      "    {\"principal\": \"mulheres\", \"apelidos\": [\"vidas das mulheres\", \"djamila ribeiro\"]}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "graphs, names, replacements = unify_graph_terms([original_graph, paraphrase_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs[0].to_csv(\"original_graph.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs[1].to_csv(\"paraphrase_graph.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity1</th>\n",
       "      <th>relationship</th>\n",
       "      <th>entity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mulheres</td>\n",
       "      <td>analisar</td>\n",
       "      <td>problema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mulheres</td>\n",
       "      <td>enfrentar</td>\n",
       "      <td>desafios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mídia</td>\n",
       "      <td>influência</td>\n",
       "      <td>trabalho de cuidado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entity1 relationship              entity2\n",
       "0  mulheres     analisar             problema\n",
       "1  mulheres    enfrentar             desafios\n",
       "2     mídia   influência  trabalho de cuidado"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(*graphs, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9638450145721436"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(original).similarity(nlp(paraphrase))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
